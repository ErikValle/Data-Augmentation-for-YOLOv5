{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Augmentation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErikValle/Data-Augmentation-for-YOLOv5/blob/main/Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLRJJEMaJJmj"
      },
      "source": [
        "# Data Augmentation for YOLOv5\n",
        "This approach uses Data Augmentation to generate new samples given a training/validation dataset without the Keras Augmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjnqr6TOJJm6"
      },
      "source": [
        "### Prerequisites\n",
        "They are the same as YOLOv5, but make sure you have already installed them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bStoFhKJJm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db9098c7-af29-45ea-ac22-1fa497428470"
      },
      "source": [
        "!git clone https://github.com/ErikValle/Data-Augmentation-for-YOLOv5.git\n",
        "%cd Data-Augmentation-for-YOLOv5/\n",
        "%ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Data-Augmentation-for-YOLOv5'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 58 (delta 17), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (58/58), done.\n",
            "/content/Data-Augmentation-for-YOLOv5\n",
            "Augmentation.ipynb  LICENSE  README.md  requirements.txt  \u001b[0m\u001b[01;34msamples\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0rwqkEGP5y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e65f849-cf87-4173-eb34-0d9cf694b531"
      },
      "source": [
        "%pip install -qr requirements.txt  # install dependencies"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 102 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 112 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 122 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 133 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 143 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 153 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 163 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 174 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 184 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 194 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 204 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 215 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 225 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 235 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 245 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 256 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 266 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 276 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 286 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 296 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 307 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 317 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 327 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 337 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 348 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 358 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 368 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 378 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 389 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 399 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 409 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 419 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 430 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 440 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 450 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 460 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 471 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 481 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 491 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 501 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 512 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 522 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 532 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 542 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 552 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 563 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 573 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 583 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 593 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 596 kB 5.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGICinmIJJnB"
      },
      "source": [
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "%config InlineBackend.figure_format='retina'\n",
        "import os\n",
        "import shutil\n",
        "from skimage.util import random_noise\n",
        "np.random.seed(42) ## random seed, change it accordingly\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXzB7f1HJJnC"
      },
      "source": [
        "## 1. Convert to YOLO format\n",
        "\n",
        "### **Recall:** YOLOv5 requires the dataset to be in the darknet format. Here’s an outline of what it looks like:\n",
        "- One txt with labels file per image\n",
        "- One row per object\n",
        "- Each row is class x_center y_center width height format.\n",
        "- Box coordinates must be in normalized xywh format (from 0 - 1). If your boxes are in pixels, divide `x_center` and `width` by image width, and `y_center` and `height` by image height.\n",
        "- Class numbers are zero-indexed (start from 0).\n",
        "\n",
        "**Example**:\n",
        "- Image properties: width=1156 pix, height=1144 pix.\n",
        "- bounding box properties: xmin=1032, ymin=20, xmax=1122, ymax=54, object_name=\"Ring\".\n",
        "- Let objects_list=\"bracelet\",\"Earring\",\"Ring\",\"Necklace\"\n",
        "\n",
        "**YOLOv5 format:** f\"{category_idx} {x1 + bbox_width / 2} {y1 + bbox_height / 2} {bbox_width} {bbox_height}\\n\"\n",
        "- $bbox_{width} = x_{max}/width - x_{min}/width = (1122-1032)/1156 = 0.07785467128027679$\n",
        "- $bbox_{height} = y_{max}/height - y_{min}/height = (54-20)/1144 = 0.029720279720279717$ \n",
        "- $x_{center}=x_{min}/width+bbox_{width}/2 = 0.9316608996539792$\n",
        "- $y_{center}=y_{min}/height + bbox_{height}/2 = 0.032342657342657344$\n",
        "- category_idx=2\n",
        "- Final result: **2 0.9316608996539792 0.032342657342657344 0.07785467128027679 0.029720279720279717**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3ErrXv4JJnF"
      },
      "source": [
        "def read_files(img_dir, lbl_dir):\n",
        "  img_dataset = [] \n",
        "  lbls_dataset = []\n",
        "  img_names = []\n",
        "  images = os.listdir(img_dir)\n",
        "  for i, image_name in enumerate(tqdm(images)): #Load images and labels from source\n",
        "    image = cv2.imread(img_dir+'/'+image_name)\n",
        "    img_names.append(image_name)\n",
        "    img_dataset.append(np.array(image))\n",
        "    with open(lbl_dir+'/'+image_name.split('.')[0]+'.txt') as f:\n",
        "        lbls_dataset.append(f.readlines())\n",
        "        lbls_dataset[i][0]=lbls_dataset[i][0].replace('\\n', '').split(' ') #remove unwanted characters and split data\n",
        "  return img_dataset, lbls_dataset, img_names"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vc0rJw9JJnH"
      },
      "source": [
        "### Data Reading and Storage Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1L_jpKbJJnJ"
      },
      "source": [
        "def find_data(labels_dataset, typ):\n",
        "    \"\"\"\n",
        "    Description: Find files with the given category.\n",
        "    labels_dataset = list\n",
        "    typ = int, numberic value of the desired category to be found \n",
        "    \"\"\"\n",
        "    index=[]\n",
        "    for d in range(len(labels_dataset)):\n",
        "        if int(labels_dataset[d][0][0])==typ:\n",
        "            index.append(d)\n",
        "    if len(index) == 0:\n",
        "        print('The dataset does not contain any requested label')\n",
        "    return index\n",
        "def xml2dim(labels_dataset):\n",
        "    \"\"\"\n",
        "    Description: Clean and organize the given labels_dataset\n",
        "    labels_dataset = list\n",
        "    \"\"\"\n",
        "    lbl=labels_dataset[0][0] #category\n",
        "    a=float(labels_dataset[0][1]) #box center X\n",
        "    b=float(labels_dataset[0][2]) #box center Y\n",
        "    bbox_width=float(labels_dataset[0][3]) #box width\n",
        "    bbox_height=float(labels_dataset[0][4]) #box height\n",
        "    return lbl, a, b, bbox_width, bbox_height\n",
        "def create_imgnlbl(name, lbl, img, x1, x2, y1, y2):\n",
        "    \"\"\"\n",
        "    Description: Save augmented image and label in a pre-defined directory\n",
        "    name=file name without extension (str)\n",
        "    lbl = category number(int)\n",
        "    img= MxN list\n",
        "    x1, x2, y1, y2 = coordinates of bbox\n",
        "    Note: Modify the label and image directories accordingly\n",
        "    \"\"\"\n",
        "    labels_path = Path(f\"{labels_directory}\")#labels path\n",
        "    h,w,_=img.shape\n",
        "    x1, y1 = x1/w, y1/h #escalate x and y (0 to 1)\n",
        "    x2, y2 = x2/w, y2/h\n",
        "    bbox_width = x2 - x1\n",
        "    bbox_height = y2 - y1\n",
        "    cv2.imwrite(image_directory+\"/\"+name+'.jpg', img)\n",
        "    name_l=name+\".txt\"\n",
        "    with (labels_path/name_l).open(mode=\"w\") as label_file:\n",
        "        label_file.write(\n",
        "            f\"{lbl} {x1 + bbox_width / 2} {y1 + bbox_height / 2} {bbox_width} {bbox_height}\\n\"\n",
        "        )\n",
        "    return\n",
        "def create_lblbox(img, lbl, x1, x2, y1, y2):\n",
        "    \"\"\"\n",
        "    Description: Create a label in the YOLOv5 format\n",
        "    lbl = category number(int)\n",
        "    x1, x2, y1, y2 = coordinates of bbox\n",
        "    Note: Modify the label and image directories accordingly\n",
        "    \"\"\"\n",
        "    h,w,_=img.shape\n",
        "    x1, y1 = x1/w, y1/h #escalate x and y (0 to 1)\n",
        "    x2, y2 = x2/w, y2/h\n",
        "    bbox_width = x2 - x1\n",
        "    bbox_height = y2 - y1\n",
        "    return [[float(lbl), float(x1 + bbox_width / 2), float(y1 + bbox_height / 2), float(bbox_width), float(bbox_height)]]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eL5Z8XDJJnM"
      },
      "source": [
        "### Photometric Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVU8jk6oJJnP"
      },
      "source": [
        "#The following lines are just for your reference, uncomment them and paste them in sectin \"Generating samples with TTA\" as required\n",
        "\"\"\"\n",
        "img_gnoise = (255*random_noise(img, mode='gaussian', var=0.05**2)).astype(np.uint8) #_GN\n",
        "img_lnoise = (255*random_noise(img, mode='localvar')).astype(np.uint8) #_LN\n",
        "img_psnoise = (255*random_noise(img, mode='poisson')).astype(np.uint8) #_PN\n",
        "img_snoise = (255*random_noise(img, mode='salt', amount=0.05)).astype(np.uint8) #_SN\n",
        "img_ppnoise = (255*random_noise(img, mode='pepper', amount=0.05)).astype(np.uint8) #_PP\n",
        "img_spnoise = (255*random_noise(img, mode='s&p', amount=0.05, salt_vs_pepper=0.5)).astype(np.uint8) #_SP\n",
        "img_spknoise = (255*random_noise(img, mode='speckle')).astype(np.uint8) #_SE\n",
        "img_gray = cv2.cvtColor(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), cv2.COLOR_GRAY2BGR) #_GR\n",
        "img_HE = cv2.cvtColor(cv2.equalizeHist(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)),cv2.COLOR_GRAY2BGR) #_HE\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB1PlV4gJJnS"
      },
      "source": [
        "### Geometric Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7iTCjdpJJnS"
      },
      "source": [
        "def shear(img,labels_dataset,shx,shy):\n",
        "    \"\"\"\n",
        "    Description: Shear transformation and its corresponding bounding box coordinates\n",
        "    img= MxN list\n",
        "    labels_dataset = list\n",
        "    shx, shy = float\n",
        "    \"\"\"\n",
        "    M = np.float32([[1, shx, 0],[shy, 1  , 0],[0, 0  , 1]])\n",
        "    sheared_img = cv2.warpPerspective(img,M,(int(img.shape[1]*(1+shx)),int(img.shape[0]*(1+shy))))\n",
        "    _,a,b,bbox_width,bbox_height=xml2dim(labels_dataset)\n",
        "    h,w,_=img.shape\n",
        "    x1, y1 = np.round_((a-bbox_width/2)*w,0), np.round_((b-bbox_height/2)*h,0)\n",
        "    x2, y2 = np.round_((a+bbox_width/2)*w,0), np.round_((b+bbox_height/2)*h,0)\n",
        "    #Affine Transformation\n",
        "    u1, u2=int(M[0][0]*x1+M[0][1]*y1+M[0][2]), int(M[0][0]*x2+M[0][1]*y2+M[0][2])\n",
        "    v1, v2=int(M[1][0]*x1+M[1][1]*y1+M[1][2]), int(M[1][0]*x2+M[1][1]*y2+M[1][2])\n",
        "    return sheared_img, u1, u2, v1, v2\n",
        "def flip(img,labels_dataset,mode):\n",
        "    \"\"\"\n",
        "    Description: Flip an image and its corresponding bounding box coordinates\n",
        "    img= MxN list\n",
        "    labels_dataset = list\n",
        "    modes: \n",
        "        0 = left to right\n",
        "        1 = up to down \n",
        "    \"\"\"\n",
        "    _,a,b,bbox_width,bbox_height=xml2dim(labels_dataset)\n",
        "    h,w,_=img.shape\n",
        "    if mode==0:\n",
        "        a=1-a\n",
        "        flip_img=cv2.flip(img,1)\n",
        "    elif mode==1:\n",
        "        b=1-b\n",
        "        flip_img=cv2.flip(img,0)\n",
        "    else:\n",
        "        print('Your selected mode does not exist')\n",
        "        return\n",
        "    x1, y1 = np.round_((a-bbox_width/2)*w,0), np.round_((b-bbox_height/2)*h,0)\n",
        "    x2, y2 = np.round_((a+bbox_width/2)*w,0), np.round_((b+bbox_height/2)*h,0)\n",
        "    return flip_img, x1, x2, y1, y2\n",
        "def rotate(img,labels_dataset,mode):\n",
        "    \"\"\"\n",
        "    Description: Rotate an image and its corresponding bounding box coordinates\n",
        "    img= MxN list\n",
        "    labels_dataset = list\n",
        "    modes: \n",
        "        0 = 90° counterclockwise\n",
        "        1 = 180°\n",
        "        2 = 270° counterclowise / 90° clockwise\n",
        "    \"\"\"\n",
        "    _,a,b,bbox_width,bbox_height=xml2dim(labels_dataset)\n",
        "    h,w,_=img.shape\n",
        "    if mode==0:\n",
        "        rot_img=cv2.rotate(img, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "        x1, y1 = np.round_((b-bbox_height/2)*h,0), np.round_((1-a-bbox_width/2)*w,0)\n",
        "        x2, y2 = np.round_((b+bbox_height/2)*h,0), np.round_((1-a+bbox_width/2)*w,0)\n",
        "    elif mode==1:\n",
        "        rot_img=cv2.rotate(img, cv2.cv2.ROTATE_180)\n",
        "        a=1-a\n",
        "        b=1-b\n",
        "        x1, y1 = np.round_((a-bbox_width/2)*w,0), np.round_((b-bbox_height/2)*h,0)\n",
        "        x2, y2 = np.round_((a+bbox_width/2)*w,0), np.round_((b+bbox_height/2)*h,0)\n",
        "    elif mode==2:\n",
        "        rot_img=cv2.rotate(img, cv2.cv2.ROTATE_90_CLOCKWISE)\n",
        "        x1, y1 = np.round_((1-b-bbox_height/2)*h,0), np.round_((a-bbox_width/2)*w,0)\n",
        "        x2, y2 = np.round_((1-b+bbox_height/2)*h,0), np.round_((a+bbox_width/2)*w,0)\n",
        "    else:\n",
        "        print('Your selected mode does not exist')\n",
        "        return\n",
        "    return rot_img, x1, x2, y1, y2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqrbOFfdJJnU"
      },
      "source": [
        "### Random Occlusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuEkZ4odJJnV"
      },
      "source": [
        "def rand_erasing(img,labels_dataset,mode):\n",
        "    \"\"\"\n",
        "    Description: Random erasing in an image\n",
        "    img= MxN list\n",
        "    labels_dataset = list\n",
        "    modes: \n",
        "        0 = Object-aware Random Erasing (ORE)\n",
        "        1 = Image-aware Random Erasing (IRE)\n",
        "        2 = Image and object-aware Random Erasing (I+ORE)\n",
        "    \"\"\"\n",
        "    im=img\n",
        "    _,a,b,bbox_width,bbox_height=xml2dim(labels_dataset)\n",
        "    h,w,_=im.shape\n",
        "    x1, y1 = np.round_((a-bbox_width/2)*w,0), np.round_((b-bbox_height/2)*h,0)\n",
        "    x2, y2 = np.round_((a+bbox_width/2)*w,0), np.round_((b+bbox_height/2)*h,0)\n",
        "    xe, ye = x2, y2\n",
        "    We, He = 1, 1\n",
        "    if (mode==0):\n",
        "        while not(xe+We<=x2 and ye+He<=y2):\n",
        "            xe=np.random.choice(range(int(x1),int(x2)))\n",
        "            ye=np.random.choice(range(int(y1),int(y2)))\n",
        "            re=np.random.rand()*0.7# maximum % of total bbox area\n",
        "            Se=int((x2-x1)*(y2-y1)*np.random.rand())\n",
        "            He=int(np.round(np.sqrt(Se*re),0))\n",
        "            We=int(np.round(np.sqrt(Se/re),0))\n",
        "        # Rectangle Ie=(xe,ye,xe+We, ye+He)\n",
        "        for i in range(ye,ye+He):\n",
        "            for j in range(xe,xe+We):\n",
        "                val=np.random.choice(range(0,255))\n",
        "                im[i][j][0]=val\n",
        "                im[i][j][1]=val\n",
        "                im[i][j][2]=val\n",
        "    elif (mode==1):\n",
        "        h1=int(np.round_(np.random.choice(range(0,int(h)))*0.5,0))# maximum % of total image area\n",
        "        w1=int(np.round_(np.random.choice(range(0,int(w)))*0.5,0))# maximum % of total image area\n",
        "        h2=int(np.round_(np.random.choice(range(h1,int(h))),0))\n",
        "        w2=int(np.round_(np.random.choice(range(w1,int(w))),0))\n",
        "        for i in range(h1,h2):\n",
        "            for j in range(w1,w2):\n",
        "                val=np.random.choice(range(0,255))\n",
        "                im[i][j][0]=val\n",
        "                im[i][j][1]=val\n",
        "                im[i][j][2]=val\n",
        "    elif mode==2:\n",
        "        while not(xe+We<=x2 and ye+He<=y2):\n",
        "            xe=np.random.choice(range(int(x1),int(x2)))\n",
        "            ye=np.random.choice(range(int(y1),int(y2)))\n",
        "            re=np.random.rand()*0.7# maximum % of total bbox area\n",
        "            Se=int((x2-x1)*(y2-y1)*np.random.rand())\n",
        "            He=int(np.round(np.sqrt(Se*re),0))\n",
        "            We=int(np.round(np.sqrt(Se/re),0))\n",
        "        # Rectangle Ie=(xe,ye,xe+We, ye+He)\n",
        "        for i in range(ye,ye+He):\n",
        "            for j in range(xe,xe+We):\n",
        "                val=np.random.choice(range(0,255))\n",
        "                im[i][j][0]=val\n",
        "                im[i][j][1]=val\n",
        "                im[i][j][2]=val\n",
        "        h1=int(np.round_(np.random.choice(range(0,int(h)))*0.5,0))# maximum % of total image area\n",
        "        w1=int(np.round_(np.random.choice(range(0,int(w)))*0.5,0))# maximum % of total image area\n",
        "        h2=int(np.round_(np.random.choice(range(h1,int(h))),0))\n",
        "        w2=int(np.round_(np.random.choice(range(w1,int(w))),0))\n",
        "        for i in range(h1,h2):\n",
        "            for j in range(w1,w2):\n",
        "                val=np.random.choice(range(0,255))\n",
        "                im[i][j][0]=val\n",
        "                im[i][j][1]=val\n",
        "                im[i][j][2]=val\n",
        "    else:\n",
        "        print('Your selected mode does not exist')\n",
        "        return\n",
        "    return im"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qb8exSCJJnX"
      },
      "source": [
        "### Deep Learning based Approaches (experimental)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CcIa_U8JJnY"
      },
      "source": [
        "model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
        "def load_image(img):\n",
        "    #img = tf.io.read_file(img_path)\n",
        "    #img = tf.image.decode_image(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = img[tf.newaxis, :]\n",
        "    return img\n",
        "content_image = load_image(image_dataset[22])\n",
        "style_image = load_image(image_dataset[539])\n",
        "stylized_image = model(tf.constant(content_image), tf.constant(style_image))[0]\n",
        "plt.imshow(np.squeeze(stylized_image))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgANeC6LJJna"
      },
      "source": [
        "### Suggested Labeling for TTA\n",
        "- gaussian noise: _GN\n",
        "- localvar noise: _LN\n",
        "- poisson noise: _PN\n",
        "- salt noise: _SN\n",
        "- pepper noise: _PP\n",
        "- salt&pepper: _SP\n",
        "- speckle noise:_SE\n",
        "- gray: _GR\n",
        "- Histogram Equalization: _HE\n",
        "\n",
        "- shear x: _SX\n",
        "- shear y: _SY\n",
        "- flip lr: _LR\n",
        "- flip ud: _UD\n",
        "- rotation 90: _R90\n",
        "- rotation 180: _R180\n",
        "- rotation 270: _R270\n",
        "- random erasing: img _RE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy7dQ4CURbox"
      },
      "source": [
        "### Generating samples with TTA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhCPHx_GJJnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f8de0af-60ba-4744-fa52-9600a6ae4c15"
      },
      "source": [
        "image_directory = 'samples/images/train'\n",
        "labels_directory = 'samples/labels/train'\n",
        "image_dataset, labels_dataset, image_names=read_files(image_directory,labels_directory)\n",
        "etiqueta=2\n",
        "cat_lbls=find_data(labels_dataset, etiqueta)\n",
        "bsize=1 #number of samples to be selected randomly\n",
        "select=np.random.choice(cat_lbls, bsize, replace=False)\n",
        "for c in tqdm(range(len(select))):\n",
        "    index=select[c]\n",
        "    img=image_dataset[index]\n",
        "    lbl_dataset=labels_dataset[index]\n",
        "    nombre=image_names[index].split('.')[0]\n",
        "    \n",
        "    # The following three lines generate coordinates for photometric transformations only\n",
        "    _, a, b, bbox_width, bbox_height=xml2dim(lbl_dataset)#lbl, a, b, bbox_width, bbox_height\n",
        "    w = int(img.shape[1])\n",
        "    h = int(img.shape[0])\n",
        "    x1, y1 = np.round_((a-bbox_width/2)*w,0), np.round_((b-bbox_height/2)*h,0)\n",
        "    x2, y2 = np.round_((a+bbox_width/2)*w,0), np.round_((b+bbox_height/2)*h,0)\n",
        "    \n",
        "    img_gnoise = (255*random_noise(img, mode='gaussian', var=0.05**2)).astype(np.uint8) #_GN\n",
        "    create_imgnlbl(nombre+\"_GN\", etiqueta, img_gnoise, x1, x2, y1, y2)\n",
        "    \n",
        "    img_spnoise = (255*random_noise(img, mode='s&p', amount=0.05, salt_vs_pepper=0.5)).astype(np.uint8) #_SP\n",
        "    create_imgnlbl(nombre+\"_SP\", etiqueta,  img_spnoise, x1, x2, y1, y2)\n",
        "        \n",
        "    img_shx, x1_sx, x2_sx, y1_sx, y2_sx=shear(img,lbl_dataset,0.01,0) #sheared_img, u1, u2, v1, v2 _SX\n",
        "    create_imgnlbl(nombre+\"_SX\", etiqueta, img_shx, x1_sx, x2_sx, y1_sx, y2_sx)\n",
        "    \n",
        "    img_shy, x1_sy, x2_sy, y1_sy, y2_sy=shear(img,lbl_dataset,0,0.01) #sheared_img, u1, u2, v1, v2 _SY\n",
        "    create_imgnlbl(nombre+\"_SY\", etiqueta, img_shy, x1_sy, x2_sy, y1_sy, y2_sy)\n",
        "    \n",
        "    img_fliplr, x1_fl, x2_fl, y1_fl, y2_fl=flip(img,lbl_dataset,0) #flip_img, x1, x2, y1, y2 _LR\n",
        "    create_imgnlbl(nombre+\"_LR\", etiqueta, img_fliplr, x1_fl, x2_fl, y1_fl, y2_fl)\n",
        "    \n",
        "    img_flipud, x1_fu, x2_fu, y1_fu, y2_fu=flip(img,lbl_dataset,1) #flip_img, x1, x2, y1, y2 _UD\n",
        "    create_imgnlbl(nombre+\"_UD\", etiqueta, img_flipud, x1_fu, x2_fu, y1_fu, y2_fu)\n",
        "    \n",
        "    img_r90,x1_90, x2_90, y1_90, y2_90 =rotate(img,lbl_dataset,0) #rot_img, x1, x2, y1, y2 _R90\n",
        "    create_imgnlbl(nombre+\"_R90\", etiqueta, img_r90,x1_90, x2_90, y1_90, y2_90)\n",
        "    \n",
        "    img_r180,x1_180, x2_180, y1_180, y2_180 =rotate(img,lbl_dataset,1) #rot_img, x1, x2, y1, y2 _R180\n",
        "    create_imgnlbl(nombre+\"_R180\", etiqueta, img_r180,x1_180, x2_180, y1_180, y2_180)\n",
        "    \n",
        "    img_r270,x1_270, x2_270, y1_270, y2_270 =rotate(img,lbl_dataset,2) #rot_img, x1, x2, y1, y2 _R270\n",
        "    create_imgnlbl(nombre+\"_R270\", etiqueta, img_r270,x1_270, x2_270, y1_270, y2_270)\n",
        "    \n",
        "    img_re=rand_erasing(img,lbl_dataset,2) #img _RE\n",
        "    create_imgnlbl(nombre+\"_RE\", etiqueta, img_re, x1, x2, y1, y2)\n",
        "    \n",
        "    \"\"\"\n",
        "    ## RANDOM GENERATOR\n",
        "    choice=np.random.choice([0, 1, 2], 1, p=[0.46, 0.27, 0.27])\n",
        "    if choice[0]==0: #shear\n",
        "        img_shx, x1_sx, x2_sx, y1_sx, y2_sx=shear(img,lbl_dataset,0.01,0)\n",
        "        create_imgnlbl(nombre+\"_SX\", etiqueta, img_shx, x1_sx, x2_sx, y1_sx, y2_sx)\n",
        "    elif choice[0]==1: #gaussian noise\n",
        "        img_gnoise = (255*random_noise(img, mode='gaussian', var=0.05**2)).astype(np.uint8)\n",
        "        create_imgnlbl(nombre+\"_G\", etiqueta, img_gnoise, x1, x2, y1, y2)\n",
        "    elif choice[0]==2: #random erasing\n",
        "        img_re=rand_erasing(img,lbl_dataset,2) #img _RE\n",
        "        create_imgnlbl(nombre+\"_RE\", etiqueta, img_re, x1, x2, y1, y2)\n",
        "    \"\"\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:00<00:00, 53.80it/s]\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.02s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdzBkIR_SPam"
      },
      "source": [
        "### Plot the new images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u3XlY-jRHMp"
      },
      "source": [
        "image_dataset, labels_dataset, image_names=read_files()\n",
        "img1 = cv2.cvtColor(cv2.imread(image_dataset[0], cv2.COLOR_BGR2RGB)\n",
        "plt.figure(1)\n",
        "plt.subplot(141)\n",
        "plt.imshow(img1)\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}